# Тестовое задание для Altium

## Задание

На входе есть большой текстовый файл, где каждая строка имеет вид Number. String. 
Например:

415\. Apple

30432\. Something something something

1\. Apple

32\. Cherry is the best

2\. Banana is yellow


Обе части могут в пределах файла повторяться. Необходимо получить на выходе другой файл, где все строки отсортированы. Критерий сортировки: сначала сравнивается часть String, если она совпадает, тогда Number. Т.е. в примере выше должно получиться

1\. Apple

415\. Apple

2\. Banana is yellow

32\. Cherry is the best

30432\. Something something something

Требуется написать две программы:
1. Утилита для создания тестового файла заданного размера. Результатом работы должен быть текстовый файл описанного выше вида. Должно быть какое-то количество строк с одинаковой частью String.
2. Собственно сортировщик. Важный момент, файл может быть очень большой. Для тестирования будет использоваться размер ~100Gb.  
## Решение

Решение состоит из трех проектов написанных на C# для платформы .Net:
- **FileGenerator**, консольное приложение для генерации файлов согласно заданию. Принимает два параметра:
  - Путь для генерируемого файла. Если параметр не указан, то будет сгенерирован файл 1gb.txt в текущей директории.
  - Размер файла. Значение по умолчанию 1073741824 (1GB).
- **BigSorter**, консольное приложение, которое реализует поставленную задачу. Принимает два параметра: 
  - Путь к текстовому файлу. Если не указан, то будет попытка прочитать файл 1gb.txt из текущей директории.
  - Число, которое определяет какой объем памяти будет использоваться для загрузки части данных из входного файла. Значение по умолчанию 1073741824 (1GB)
- **BigSorter.Tests**, проект с юнит-тестами для *BigSorter*, в котором используется Xunit юнит-тест фреймфорк.

Данную задачу можно обобщить до задачи сортировки больших, не помещающихся в оперативную память, табличных данных по одному и более полей. Именно в таком виде данная задача изначально и решалась. Позже в целях увеличения производительности, решение было частично сужено до сортировки данных конкретного вида: <число. строка>. Однако, несложно дополнить программу так, что она сможет сортировать большие таблицы с произвольным набором полей произвольного типа.  

## Алгоритм

За основу сортировки больших данных взят алгоритм [External Sorting](https://en.wikipedia.org/wiki/External_sorting), в котором сортировка происходит в два этапа:

1. Этап сортировки. Данные загружаются по-блочно, так чтобы каждый блок мог поместится в память. Каждый блок сортируется, используя обычный алгоритм сортировки, например Quick Sort. Затем отсортированный блок сохраняется во временный файл.

2. Этап слияния. На этом этапе используется алгоритм [k-way sorting](https://en.wikipedia.org/wiki/K-way_merge_algorithm). Данные из каждого блока по частям загружаются в оперативную память. Для каждой части блока хранится индекс, указывающий на текущий элемент, изначально указывающий на первый. Среди элементов, на которые указывают индексы, выбирается  наименьший. Этот элемент записывается в отдельно выделенную область памяти. Когда какой-либо из индексов достигает конца части блока - подгружается следующая часть блока. Когда область памяти выделенная для хранения наименьших элементов заполнятся, происходит ее запись в выходной файл. Данный процесс повторяется пока элементы из всех блоков не будут обработаны и на выходе будет получен полностью отсортированный файл.

Пусть n - число элементов, а k - число блоков. Тогда вычислительная сложность первого этапа при использовании QuickSort будет *O(n\*log(n/k))*. Если на этапе слияния в качестве структуры для хранения индексов использовать binary min heap, то вычислительная сложность второго этапа будет *O(n\*log(k))*. Суммарная вычислительная сложность алгоритма будет *O(n\*log(n/k) + n\*log(k))*

Так как по условию задания данные необходимо сортировать сначала по одному полю, а затем по другому, то алгоритм external sorting повторяется для сортировки сначала по строке, а затем для каждой группы записей с одинаковой строкой - по числу. При этом если размер данных требуемый для сортировки помещается в оперативную память, то производится обычная QuickSort. 

На много-ядерных/процессорных системах производительность может быть повышена за счет распараллеливания некоторых шагов алгоритма:

- Сортировка блоков может выполнятся с использованием параллельной сортировки. В данном решении параллельная сортировка выполнена следующим образом:
  - Блок делится на части, количество которых равно количеству ядер/процессоров. 
  - Каждая часть сортируется в отдельном потоке. 
  - Затем выполняется слияние отсортированных частей в один отсортированный массив.
 Если m - количество ядер/процессоров, то время выполнения всего алгоритма сортировки с учетом данной оптимизации можно оценить как *O(n/m\*log(n/k/m) + n\*log(m) + n\*log(k))*

- Как только какой-то блок считался из файла сразу можно запустить считывание следующего блока, а сортировку предыдущего запустить в отдельном потоке. Это даст некоторый прирост в производительности, так как считывание данных из файловой системы является медленной операцией. При этом размер блоков должен быть уменьшен, поскольку в данном случае сразу несколько блоков может находится в оперативной памяти.

## Классы и интерфейсы

### BigTableSorter
```C#
public class BigTableSorter
{
  public BigTableSorter(ITempStreams tempStreams, long maxBufferSizeInBytes, int maxWorkersCount = -1)
  { … }

  public void Sort(Stream input, int[] fields, Stream output)
  { … }
}
```
Класс `BigTableSorter` реализует алгоритм сортировки больших таблиц, описанный выше с учетом оптимизаций для много-ядерных/процессорных систем.  

Через конструктор объект этого класса параметризуется следующими параметрами:
- `tempStreams` объект типа  `ITempStreams`, который предназначен для доступа к хранилищу временных данных. В решении есть две реализации этого интерфейса. Одна `FileTempStreams` - для хранения временных данных в файловой системе. Находится в проекте BigSorter. Другая `TempStreams` - для хранения в оперативной памяти. Находится в проекте BigSorter.Tests. Данная реализация используется в unit-тестах.
- `maxBufferSizeInBytes` - этот параметр указывает максимальное количество памяти, которое будут занимать загруженные данные.
- `maxWorkersCount` - задает какое количество потоков будет создано для одновременной подгрузки и сортировки блоков.

Класс `BigTableSorter` имеет метод `Sort`, который реализует сортировку. На вход данный метод получает:
- Входной поток, с которого данные будут считываться.
- Массив с индексами полей, по которым будет происходить сортировка. Для данного задания этот массив будет содержать элементы [1, 0]. 1 - сортировка сначала по второму полю, то есть по строке, 0 - затем сортировка по первому полю, то есть по числу.
- Выходной поток, куда будут записаны отсортированные данные.

### RecordsBuffer
```C#
public class RecordsBuffer
{
  public RecordsBuffer(long maxSizeInBytes)
  { … }

  public bool AddRecord(Record record)
  { … }

  public void Sort(int field)
  { … }
 }
 ```

Класс `RecordsBuffer` предназначен для хранения части данных, размер которых не должен превышать заданный предел. Значение предела передается через конструктор. Метод `AddRecord` добавляет запись в буфер если предел не превышен. Метод `Sort` сортирует записи по заданному полю. 

### Record
```C#
public struct Record
{
  public readonly int Number;
  public readonly string String;
}
```
Структура `Record` предназначена для хранения одной записи согласно условию задания: число и строка. Данный тип данных реализован как value type используя `struct` вместо `class` из соображений производительности. 

### RecordsReader
```C#
public class RecordsReader
{
  public RecordsReader(StreamReader streamReader, long bufferSizeInBytes, int readWhileSameFieldValue = -1)
  { … }

  public IEnumerable<RecordsBuffer> ReadBlocks()
  { … }

  public IEnumerable<Record> ReadRecords()
  { … }
}
```
Класс `RecordsReader` предназначен для записей из текстового потока. Он имеет два метода:
- `ReadBlocks`, который считывает и возвращает данные по-блочно. Этот метод используется на первом этапе сортировки блоков.
- `ReadRecords`, данный метод также считывает данные по-блочно, но перечисляет отдельные записи, возвращая `IEnumerable<Record>`. Этот метод используется на этапе слияния, когда каждый отдельный блок в свою очередь должен загружаться по частям. Возвращение отдельных записей, вместо частей делает более простым реализацию слияния, так как для кода выполняющего слияние чтение блока выглядит как чтение всего блока целиком, а не чтение отдельных его частей. 

### RecordsWriter
```C#
public class RecordsWriter
{
  public RecordsWriter(TextWriter textWriter)
  { … }

  public void WriteRecords(RecordsBuffer buffer)
  { … }
}
```
Класс `RecordsWriter` предназначен для записи данных в текстовый поток. Он имеет метод `WriterRecords` который записывает все записи из `RecordsBuffer`. Данный метод используется на этапе сортировки блоков для записи их во временное хранилище.

### BufferedRecordsWriter
```C#
public class BufferedRecordsWriter : IDisposable
{
  public BufferedRecordsWriter(TextWriter textWriter, long bufferSizeInBytes)
  { … }

  public void WriteRecord(Record record)
  { … }

  public void Flush()
  { … }
}
```
Класс `BufferedRecordsWriter` предназначен для записывания записей в текстовый поток. При этом сначала записи добавляются в буфер и когда буфер заполняется весь буфер пишется в текстовый поток. Метод `WriteRecord` этого класса используется сортировщиком на этапе слияния, делая более простым реализацию слияния, так как для кода выполняющего слияние записывание записей выглядит как будто они записываются одна за другой, скрывая детали буферизации.

### RecordParser
```C#
public class RecordParser
{
  public Record Parse(string s) 
  { }

  public string ToString(Record record) 
  { }
}
```
Класс `RecordParser` предназначен для конвертирования объекта типа `Record` в строку и обратно.

### MinHeap
```C#
public class MinHeap<T>
{
  public MinHeap(int capacity, IComparer<T> comparer)
  { }

  public int Size { get; private set; }

  public T Root { get { return _array[1]; } }

  public void Add(T elem)
  { }

  public T Extract()
  { }

  public void UpHeap()
  { }

  public void DownHeap()
  { }
}
```
Класс `MinHeap` реализует min binary heap структуру данных, которая используется сортировщиком на этапе слияния для эффективного поиска минимального элемента среди всех блоков.

### ParallelSorter
```C#
public static class ParallelSorter
{
  public static List<T> ParallelSort<T>(this List<T> list, IComparer<T> comparer, int chunkCount, int threshold)
  { }

  public static List<T> ParallelSort<T>(this List<T> list, IComparer<T> comparer)
  {
    return ParallelSort(list, comparer, Environment.ProcessorCount, 4096);
  }
}
```
Класс `ParallelSorter` реализует параллельную сортировку списка элементов. Список разбивается на части, каждая из которых сортируется отдельным потоком, используя стандартную .Net реализацию сортировки списка. Затем происходит слияние отсортированных частей в отдельный полностью отсортированный список.

## Тестирование производительности

Тестирование происходило на следующей системе:
- CPU i7-860
- Memory 8GB
- Samsung SSD 840 PRO 256GB

Тестировались файлы размером 1GB, 10GB и 30GB.
Были получены такие результаты:

|   1GB    |   10GB   |   30GB   |
| -------- | -------- |----------|
| 00:03:12 | 00:40:04 | 01:52:55 |

## Возможные пути улучшения производительности 

- При сортировке по числовому полю происходит сначала загрузка группы записей с одним строковым значением, сортировка и запись в выходной файл, затем загрузка группы со следующим строковым значением и так далее. Если количество записей в одной такой группе велико, то сортировка будет распараллелена как описано выше в алгоритме. Однако, если количество записей в группе мало и таких групп, идущих одна за другой, много, то все они сортируются по очереди только одним процессором или ядром. Такие маленькие группы, идущие одна за другой, можно было бы сортировать также параллельно, соблюдая порядок записи их в выходной файл. Предполагаемый выигрыш от такой оптимизации мог бы составить около 5%-15%.

- В примере указанном в задании все строки составлены из букв английского алфавита. Если принять, что строки всегда составлены из букв английского алфавита, то можно реализовать сортировку с гораздо лучшими показателями производительности. 10GB данных будут сортироваться приблизительно 6 минут на вышеуказанной системе. Производительность можно улучшить за счет следующего: 

  - Из файла в память загружать сырые данные в байтовый буффер, без конвертирования строк в .Net тип String.

  - Эти же сырые данные из буффера будут записываться в выходной файл, без обратного конвертирования String и Int32 в байтовую последовательность.

  - Строковые части записей сравнивать в сразу в буффере:
    - в unsafe контексте, чтобы минимизировать затраты на проверку границ массива
    - выполнять проверку на равенство сначала сразу по 8 байт используя тип `long`, затем если найдено неравенство по 4 байта используя `int`, потом по 2, используя `short` и в конце сравнить 2 отличающихся байта. 
    Код сравнения:
    
```C#
unsafe public int Compare(Record x, Record y)
{
  fixed (byte* pb = _buffer)
  {
    byte* px = pb + x.StringStart;
    byte* py = pb + y.StringStart;

    int diff = *px - *py;
    if (diff != 0)
      return diff;

    int len = x.StringLength < y.StringLength ? x.StringLength : y.StringLength;
    while (len >= 8)
    {
      if (*((long*)px) != *((long*)py))
      {
        len = 8;
        break;
      }
      px += 8;
      py += 8;
      len -= 8;
    }

    while (len >= 4)
    {
      if (*((int*)px) != *((int*)py))
      {
        len = 4;
        break;
      }
      px += 4;
      py += 4;
      len -= 4;
    }

    while (len >= 2)
    {
      if (*((short*)px) != *((short*)py))
      {
        len = 2;
        break;
      }
      px += 2;
      py += 2;
      len -= 2;
    }

    while (len > 0)
    {
      diff = *px - *py;
      if (diff != 0)
        return diff;

      px++;
      py++;
      len--;
    }
  }
  return x.StringLength - y.StringLength;
}
```


